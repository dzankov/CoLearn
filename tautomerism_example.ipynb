{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>.rendered_html {font-size: 16px;}</style>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Conjugated machine learning is a concept where fundamental chemical laws in the form of strict mathematical relationships are directly integrated with machine learning algorithms. Conjugated models correctly predict the properties of molecules so that they satisfy the integrated chemical law.\n",
    "\n",
    "<img src='img/tau_img/figure_1.png' width='450'/>\n",
    "\n",
    "In this example, we consider the application of conjugated learning to simultaneous prediction of the tautomeric constant ($logK_{T}$) and the acidity ($pK_{a}$) of the corresponding tautomers. \n",
    "\n",
    "\n",
    "## Individual Ridge Regression: $pK_{a}$ prediction\n",
    "    \n",
    "In Ridge Regression, $pK_{a}$ prediction is calculated as\n",
    "\n",
    "$$ y_{A}^{pred} = Xw $$\n",
    "\n",
    "where $X$ is the matrix of descriptors encoding chemical compounds and $w$ are the regression weights.\n",
    "After minimising the error function\n",
    "\n",
    "$$ E_{A}(w) = (y_{A}^{exp} - y_{A}^{pred})^T(y_{A}^{exp} - y_{A}^{pred}) = \n",
    "             (y_{A}^{exp} - Xw)^T(y_{A}^{exp} - Xw) => min $$\n",
    "\n",
    "we can calculate the regression weights using the analytical expression\n",
    "\n",
    "$$ w = (X^{T}X + \\lambda I)^{-1}X^{T}y_{A}^{exp}$$\n",
    "\n",
    "where $X$ is the descriptor matrix of training compounds and $y_{A}^{exp}$ are the experimental $pK_{a}$ values. $\\lambda$ is the regularization coefficient, which controls the complexity of the model.\n",
    "\n",
    "## Individual Ridge Regression: $logK_{T}$ prediction\n",
    "\n",
    "The tautomeric equilibrium constant can be calculated as the difference in $pK_{a}$ of the tautomers\n",
    "\n",
    "$$ logK_{T} = pKa(product) - pKa(reagent) $$\n",
    "\n",
    "$$ logK_{T} = pKa(2) - pKa(1) $$\n",
    "\n",
    "In fact, the $logK_{T}$ can be modelled and predicted in two ways:\n",
    "\n",
    "**1**. Calculation of $logK_{T}$ via predicted $pK_{a}$ of tautomers\n",
    "\n",
    "The prediction of the tauomeric constant $y_{T}^{pred}$ can be calculated with predicted $pK_{a}$ of tautomers\n",
    "\n",
    "$$ y_{T}^{pred} = y_{A}^{pred}(2) - y_{A}^{pred}(1) = X_{2}w - X_{1}w = (X_{2} - X_{1})w $$\n",
    "\n",
    "$$ w = (X^{T}X + \\lambda I)^{-1}X^{T}y_{A}^{exp} $$\n",
    "\n",
    "All we need here is a $pK_{a}$ model.\n",
    "\n",
    "\n",
    "\n",
    "**2**. The tauomeric constant $y_{T}^{pred}$ can be modelled and predicted directly from the difference descriptor matrix\n",
    "\n",
    "$$ X_{21} = X_{2} - X_{1}$$\n",
    "\n",
    "$$ y_{T}^{pred} = X_{21}w $$\n",
    "\n",
    "$$ w = (X_{21}^{T}X_{21} + \\lambda I)^{-1}X_{21}^{T}y_{T}^{exp} $$\n",
    "\n",
    "where $X_{21}$ is the difference descriptor matrix of training tautomeric reactions and $y_{T}^{exp}$ are the experimental $logK_{T}$ values.\n",
    "\n",
    "## Conjugated Ridge Regression: $pK_{a}$ and $logK_{T}$ prediction\n",
    "\n",
    "The two approaches to $pK_{a}$ and $logK_{T}$ prediction can be combined into a conjugated model that is trained simultaneously on both $pK_{a}$ and $logK_{T}$ datasets.\n",
    "\n",
    "\n",
    "Error function for predicting $pK_{a}$\n",
    "$$ E_{A}(w) = (y_{A}^{exp} - y_{A}^{pred})^T(y_{A}^{exp} - y_{A}^{pred}) $$\n",
    "\n",
    "$$ E_{A}(w) = (y_{A}^{exp} - Xw)^T(y_{A}^{exp} - Xw) => min $$\n",
    "\n",
    "Error function for predicting $logK_{T}$\n",
    "$$ E_{T}(w) = (y_{T}^{exp} - y_{T}^{pred})^T(y_{T}^{exp} - y_{T}^{pred}) $$\n",
    "\n",
    "$$ E_{T}(w) = (y_{T}^{exp} - (X_{2} - X_{1})w)^T(y_{T}^{exp} - (X_{2} - X_{1})w) => min $$\n",
    "\n",
    "Conjugated error function for predicting $pK_{a}$ and $logK_{T}$\n",
    "\n",
    "$$ E(w) = \\alpha E_{T}(w) + (1 - \\alpha)E_{A}(w) + \\lambda w^{T}w => min $$ \n",
    "\n",
    "where $\\lambda$ is a regularization coefficient, while $\\alpha$ takes values from 0 to 1 and controls the trade-off between minimizing prediction errors of tautomeric constants vs acidity constants. Regression weights in the conjugated model are calculated as:\n",
    "\n",
    "$$ w = [\\alpha(X_{2} - X_{1})^{T}(X_{2} - X_{1}) + (1 - \\alpha)X^{T}X + \\lambda I]^{-1}\n",
    "\\alpha(X_{2} - X_{1})^Ty_{T}^{exp} + (1 - \\alpha)X^{T}y_{A}^{exp}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Code installation\n",
    "\n",
    "Using **conda** and **pip** is the easiest way to install all required packages. Create a new environment (named \"exp\") with Python 3.6. <br/>\n",
    "\n",
    "Run these commands in the command line:\n",
    "\n",
    "`conda create -n exp python=3.6`<br/>\n",
    "`conda activate exp` <br/>\n",
    "\n",
    "Install PyTorch package: <br/>\n",
    "\n",
    "`conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch` <br/>\n",
    "`pip install torch_optimizer` <br/>\n",
    "\n",
    "Install software to calculate 2D fragment descriptors: <br/>\n",
    "\n",
    "`pip install CGRTools CIMTools` <br/>\n",
    "\n",
    "If there is a problem with installing `CGRTools` or `CIMTools` on Windows, also install the library:\n",
    "\n",
    "`conda install libpython m2w64-toolchain -c msys2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset preparation\n",
    "\n",
    "For the demonstration we have two data sets: experimental $pK_{a}$ of organic compounds and the $logK_{T}$ of binary tautomeric reactions. Both data sets have a fixed structure:\n",
    "\n",
    "**Compound data set - SDF file**.\n",
    "\n",
    "MOL_BLOCK - *Compound structure* <br/>\n",
    "\\>  \\<temperature\\> - *temperature, K* <br/>\n",
    "293.15 <br/>\n",
    "\\>  \\<additive.1\\> - *organic solvent (or pure water)* <br/>\n",
    "water <br/>\n",
    "\\>  \\<amount.1\\> - *the amount of organic solvent in solution with water [0, 1]* <br/>\n",
    "1.0 <br/>\n",
    "\\>  \\<tabulated_constant\\> - *experimental $pK_{a}$* <br/>\n",
    "11.03\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Reaction data set - RDF file**.\n",
    "\n",
    "\n",
    "\\\\$MOL - *Reagent structure* <br/>\n",
    "\\\\$MOL - *Product strucutre* <br/>\n",
    "\\\\$DTYPE temperature - *temperature, K* <br/>\n",
    "\\\\$DATUM 353.0 <br/>\n",
    "\\\\$DTYPE additive.1 - *organic solvent (or pure water)* <br/>\n",
    "\\\\$DATUM ethanol <br/>\n",
    "\\\\$DTYPE amount.1 - *the amount of organic solvent in solution with water [0, 1]* <br/>\n",
    "\\\\$DATUM 1.0 <br/>\n",
    "\\\\$DTYPE tabulated_constant - *experimental $logK_{T}$* <br/>\n",
    "\\\\$DATUM -1.54 <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from CGRtools import SDFRead, RDFRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = SDFRead(os.path.join('data', 'tau_data', 'acidity_data.sdf')).read()\n",
    "reacts = RDFRead(os.path.join('data', 'tau_data', 'tautomerism_data.rdf')).read()\n",
    "\n",
    "print(f'The acidity data set contains {len(mols)} molecules')\n",
    "print(f'The tautomerism data set contains {len(reacts)} reactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acidity of minor tautomers is often unknown, but can be calculated using the equation\n",
    "\n",
    "$$ logK_{T} = pKa(2) - pKa(1) $$\n",
    "\n",
    "$$ pKa(2) = logK_{T} + pKa(1) $$\n",
    "\n",
    "Thus, to calculate $pKa(2)$ it is necessary to have the experimental $logK_{T}$ of the reaction and the $pKa(1)$ of the major tautomer. In addition, the $logK_{T}$ and $pKa(1)$ must be measured under the closest conditions (temperature, solvent, amount of solvent). We extracted two such examples from the $logK_{T}$ and $pKa$ datasets. These are keto-enol tautomerism reactions: one in **1,4-dioxane** and the other in **methanol**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reacts[308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'tau_data', 'data_itersection.pickle'), 'rb') as f:\n",
    "    data_stat = pickle.load(f)\n",
    "data_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/tau_img/figure_2.png' width='450'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put these two reactions in the test set, the others in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'tau_data', 'data_split.pickle'), 'rb') as f:\n",
    "    data_split = pickle.load(f)\n",
    "MOLS_TRAIN, MOLS_TEST = data_split['mols_train'], data_split['mols_test']\n",
    "REACTS_TRAIN, REACTS_TEST = data_split['reacts_train'], data_split['reacts_test']\n",
    "\n",
    "REAGENTS_TRAIN, REAGENTS_TEST = [], []\n",
    "PRODUCTS_TRAIN, PRODUCTS_TEST = [], []\n",
    "for i in REACTS_TRAIN:\n",
    "    r, p = i.molecules()\n",
    "    r.meta.update(i.meta)\n",
    "    p.meta.update(i.meta)\n",
    "    REAGENTS_TRAIN.append(r)\n",
    "    PRODUCTS_TRAIN.append(p)\n",
    "    \n",
    "for i in REACTS_TEST:\n",
    "    r, p= i.molecules()\n",
    "    r.meta.update(i.meta)\n",
    "    p.meta.update(i.meta)\n",
    "    REAGENTS_TEST.append(r)\n",
    "    PRODUCTS_TEST.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(y1_test, y2_test, y1_pred, y2_pred):\n",
    "\n",
    "    col_list = [('PRODUCT_PKA','EXP'), ('PRODUCT_PKA','PRED'),\n",
    "                ('REAGENT_PKA','EXP'), ('REAGENT_PKA','PRED'),\n",
    "                ('LOGKT','EXP'), ('LOGKT','PRED')]\n",
    "\n",
    "    col_list = pd.MultiIndex.from_tuples(col_list)\n",
    "    df = pd.DataFrame(columns=col_list)\n",
    "    #\n",
    "    df[('PRODUCT_PKA', 'EXP')] = y2_test\n",
    "    df[('PRODUCT_PKA', 'PRED')] = y2_pred.flatten()\n",
    "\n",
    "    df[('REAGENT_PKA', 'EXP')] = y1_test\n",
    "    df[('REAGENT_PKA', 'PRED')] = y1_pred.flatten()\n",
    "\n",
    "    df[('LOGKT', 'EXP')] = df[('PRODUCT_PKA', 'EXP')] - df[('REAGENT_PKA', 'EXP')]\n",
    "    df[('LOGKT', 'PRED')] = df[('PRODUCT_PKA', 'PRED')] - df[('REAGENT_PKA', 'PRED')]\n",
    "    \n",
    "    return df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Model building\n",
    "## 2.1 Individual Ridge Regression: $pK_{a}$ prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analytical expression for calculating regression weights is implemented in **IndividualRidge** estimator. Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from colearn.utils import ISIDAFragmentor\n",
    "from colearn.estimators.ridge_regression import IndividualRidge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the fragment descriptors for the given compounds ($pK_{a}$ dataset) using the **ISIDAFragmentor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAG = ISIDAFragmentor()\n",
    "FRAG.fit(MOLS_TRAIN)\n",
    "\n",
    "XA_TRAIN = FRAG.transform(MOLS_TRAIN)\n",
    "XA_TEST = FRAG.transform(MOLS_TEST)\n",
    "\n",
    "YA_TRAIN = np.array([float(i.meta['tabulated_constant']) for i in MOLS_TRAIN])\n",
    "YA_TEST = np.array([float(i.meta['tabulated_constant']) for i in MOLS_TEST])\n",
    "\n",
    "print(f'Compounds are encoded with {XA_TRAIN.shape[-1]} fragment descriptors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_RIDGE_PKA = IndividualRidge(lmb=0.001) # lmb is a regularization coefficient\n",
    "IND_RIDGE_PKA.fit(XA_TRAIN, YA_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and predict pKa for the test molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YA_PRED = IND_RIDGE_PKA.predict(XA_TEST)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['EXPERIMENTAL_PKA'] = YA_TEST.flatten()\n",
    "df['PREDICTED_PKA'] = YA_PRED.flatten()\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(df['EXPERIMENTAL_PKA'], df['PREDICTED_PKA'])\n",
    "print(f'The determination coefficient on the test set R2 = {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the same model to predict $logK_{T}$ via predicted $pK_{a}(1)$ and $pK_{a}(2)$ using the equation\n",
    "\n",
    "$$ logK_{T}^{pred} = pKa(2)^{pred} - pKa(1)^{pred} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_TEST = FRAG.transform(REAGENTS_TEST)\n",
    "X2_TEST = FRAG.transform(PRODUCTS_TEST)\n",
    "\n",
    "Y1_PRED = IND_RIDGE_PKA.predict(X1_TEST)\n",
    "Y2_PRED = IND_RIDGE_PKA.predict(X2_TEST)\n",
    "\n",
    "Y1_TEST = [float(i.meta['tabulated_constant']) for i in MOLS_TEST]\n",
    "Y2_TEST = [float(i.meta['tabulated_constant']) + float(j.meta['tabulated_constant']) for i, j in zip(REAGENTS_TEST, MOLS_TEST)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_RIDGE_PKA_RES = get_df(Y1_TEST, Y2_TEST, Y1_PRED, Y2_PRED)\n",
    "IND_RIDGE_PKA_RES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the individual model accurately predicts the $pK_{a}(1)$ of the major tautomer, but fails to predict the $pK_{a}(12)$ of the minor tautomer. This is typical because the acidities of minor tautomers are often unknown and not present in the training sets. Also, because of the high error in predicting the acidity of the minor tautomer, we have a high error in the calculated $logK_{T}$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Individual Ridge Regression: $logK_{T}$ prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analytical expression for calculating regression weights is implemented in **IndividualRidge** estimator. Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_TRAIN = FRAG.transform(REAGENTS_TRAIN)\n",
    "X2_TRAIN = FRAG.transform(PRODUCTS_TRAIN)\n",
    "\n",
    "X21_TRAIN = X2_TRAIN - X1_TRAIN\n",
    "X21_TEST = X2_TEST - X1_TEST\n",
    "\n",
    "YT_TRAIN = np.array([float(i.meta['tabulated_constant']) for i in REACTS_TRAIN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_RIDGE_LOGKT = IndividualRidge(lmb=10)\n",
    "IND_RIDGE_LOGKT.fit(X21_TRAIN, YT_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_PRED = IND_RIDGE_LOGKT.predict(X1_TEST)\n",
    "Y2_PRED = IND_RIDGE_LOGKT.predict(X2_TEST)\n",
    "YT_PRED = IND_RIDGE_LOGKT.predict(X21_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_RIDGE_LOGKT_RES = get_df(Y1_TEST, Y2_TEST, Y1_PRED, Y2_PRED)\n",
    "IND_RIDGE_LOGKT_RES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direct modelling gives more accurate predictions of $logK_{T}$, but the predicted $pK_{a}$ of tautjmers obviously do not have a physical sense. In addition, the subtraction of $X_{2} - X_{1}$ destroys the solvent and temperature descriptors, making the model unable to capture the dependence of $logK_{T}$ on reaction conditions (we see identical $logK_{T}$ predictions for the same reaction carried out under different conditions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Conjugated Ridge Regression: $pK_{a}$ and $logK_{T}$  prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjugated error function for predicting $pK_{a}$ and $logK_{T}$\n",
    "\n",
    "$$ E(w) = \\alpha E_{T}(w) + (1 - \\alpha)E_{A}(w) + \\lambda w^{T}w => min $$ \n",
    "\n",
    "where $\\lambda$ is a regularization coefficient, while $\\alpha$ takes values from 0 to 1 and controls the trade-off between minimizing prediction errors of tautomeric constants vs acidity constants. Regression weights in the conjugated model are calculated as:\n",
    "\n",
    "$$ w = [\\alpha(X_{2} - X_{1})^{T}(X_{2} - X_{1}) + (1 - \\alpha)X^{T}X + \\lambda I]^{-1}\n",
    "\\alpha(X_{2} - X_{1})^Ty_{T}^{exp} + (1 - \\alpha)X^{T}y_{A}^{exp}$$\n",
    "\n",
    "The analytical expression for calculating regression weights $w$ is implemented in **TautomerismConjugatedRidge** estimator. Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colearn.estimators.ridge_regression import TautomerismConjugatedRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conjugated model is trained simultaneously on both $pK_{a}$ and $logK_{T}$ data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_TRAIN = FRAG.transform(REAGENTS_TRAIN)\n",
    "X2_TRAIN = FRAG.transform(PRODUCTS_TRAIN)\n",
    "XA_TRAIN = FRAG.transform(MOLS_TRAIN)\n",
    "\n",
    "X1_TEST = FRAG.transform(REAGENTS_TEST)\n",
    "X2_TEST = FRAG.transform(PRODUCTS_TEST)\n",
    "XA_TEST = FRAG.transform(MOLS_TEST)\n",
    "\n",
    "YA_TRAIN = np.array([float(i.meta['tabulated_constant']) for i in MOLS_TRAIN])\n",
    "YA_TEST = np.array([float(i.meta['tabulated_constant']) for i in MOLS_TEST])\n",
    "\n",
    "YT_TRAIN = np.array([float(i.meta['tabulated_constant']) for i in REACTS_TRAIN])\n",
    "YT_TEST = np.array([float(i.meta['tabulated_constant']) for i in REACTS_TEST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONJ_RIDGE = TautomerismConjugatedRidge(alpha=0.9, lmb=0.001)\n",
    "CONJ_RIDGE.fit(X1_TRAIN, X2_TRAIN, XA_TRAIN, YT_TRAIN, YA_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_PRED = CONJ_RIDGE.predict_acidity(X1_TEST)\n",
    "Y2_PRED = CONJ_RIDGE.predict_acidity(X2_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONJ_RIDGE_RES = get_df(Y1_TEST, Y2_TEST, Y1_PRED, Y2_PRED)\n",
    "CONJ_RIDGE_RES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now clearly see that the conjugated model accurately predicts the $pK_{a}$ not only for the major tautomer, but also for the minor one! Consequently, the prediction accuracy of the $logK_{T}$ is also significantly higher.\n",
    "\n",
    "But we still see that the model does not capture the dependence of $logK_{T}$ on reaction conditions. This problem can be solved with conjugated learning based on neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Conjugated Neural Network: $pK_{a}$ and $logK_{T}$  prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We developed a special architecture of “twin” neural networks based on fully connected feed-forward multilayer NN with shared values of connection weights $w$.\n",
    "\n",
    "<img src='img/tau_img/figure_3.png' width='450'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colearn.estimators.neural_nets.tautomerism_net import TautomerismConjugatedNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = (X1_TRAIN.shape[1], 256, 128, 64)\n",
    "\n",
    "CONJ_NET = TautomerismConjugatedNet(ndim=ndim, alpha=0.9, init_cuda=False)\n",
    "CONJ_NET.fit(X1_TRAIN, X2_TRAIN, XA_TRAIN, YT_TRAIN, YA_TRAIN, \n",
    "             n_epoch=2000, batch_size=9999, lr=0.001, weight_decay=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_PRED = CONJ_NET.predict_acidity(X1_TEST)\n",
    "Y2_PRED = CONJ_NET.predict_acidity(X2_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONJ_NET_RES = get_df(Y1_TEST, Y2_TEST, Y1_PRED, Y2_PRED)\n",
    "CONJ_NET_RES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the conjugated model accurately predicts the $logK_{T}$ for reactions carried out under different conditions. \n",
    "\n",
    "**Remark**: In the Ridge Regression we can concatenate the difference descriptor matrix $X_{21}$ and the solvent and temperature descriptors (after subtraction of $X_{2} - X_{1}$), enabling the reaction conditions to be captured in the model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the final table comparing all approaches and models for the first test reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_FINAL = pd.concat([IND_RIDGE_PKA_RES.loc[0:0],\n",
    "                      IND_RIDGE_LOGKT_RES.loc[0:0],\n",
    "                      CONJ_RIDGE_RES.loc[0:0],\n",
    "                      CONJ_NET_RES.loc[0:0]])\n",
    "\n",
    "DF_FINAL['MODEL'] = ['Individual Ridge pKa', 'Individual Ridge logKT', 'Conjugated Ridge', 'Conjugated Net']\n",
    "DF_FINAL.set_index('MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for the second test reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_FINAL = pd.concat([IND_RIDGE_PKA_RES.loc[1:1],\n",
    "                      IND_RIDGE_LOGKT_RES.loc[1:1],\n",
    "                      CONJ_RIDGE_RES.loc[1:1],\n",
    "                      CONJ_NET_RES.loc[1:1]])\n",
    "\n",
    "DF_FINAL['MODEL'] = ['Individual Ridge pKa', 'Individual Ridge logKT', 'Conjugated Ridge', 'Conjugated Net']\n",
    "DF_FINAL.set_index('MODEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
